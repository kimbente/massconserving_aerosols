{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description : Train neural network model to predict one time step of M7\n",
    "Options:\n",
    "\n",
    "  --signs=<need_extra_signs_for_log_mass>\n",
    "  --classification=<train_classification_net>\n",
    "  --scale=<scaler>\n",
    "  --model=<model_version>\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from utils import standard_transform_x, standard_transform_y, get_model, train_model, create_report, calculate_stats, log_full_norm_transform_x, log_tend_norm_transform_y, create_dataloader, create_test_dataloader\n",
    "# from models import Softmax_model\n",
    "from utils import add_nn_arguments_jupyter\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# KB add for active development in models or utils\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define full path \n",
    "path_to_data = \"/home/kim/data/aerosols/aerosol_emulation_data/\"\n",
    "\n",
    "X_test = np.load(path_to_data + 'X_test.npy')\n",
    "y_test = np.load(path_to_data + 'y_test.npy')\n",
    "\n",
    "X_train = np.load(path_to_data + 'X_train.npy')\n",
    "y_train = np.load(path_to_data + 'y_train.npy')\n",
    "\n",
    "X_valid = np.load(path_to_data + 'X_val.npy')\n",
    "y_valid = np.load(path_to_data + 'y_val.npy')\n",
    "\n",
    "# Select the correct 24 columns\n",
    "X_test_24 = X_test[:, 8:]\n",
    "X_train_24 = X_train[:, 8:] \n",
    "\n",
    "y_test_24 = y_test[:, :24]\n",
    "y_train_24 = y_train[:, :24]\n",
    "\n",
    "y_valid_24 = y_valid[:, :24]\n",
    "X_valid_24 = X_valid[:, 8:]\n",
    "\n",
    "# How much has it changes between x (at t = 0)  and y (at t = 1)\n",
    "y_delta_train_24 = y_train_24 - X_train_24\n",
    "y_delta_test_24 = y_test_24 - X_test_24\n",
    "y_delta_valid_24 = y_valid_24 - X_valid_24\n",
    "\n",
    "# Define column indices for each of the components (24 column version)\n",
    "so4_indices = [0, 1, 2, 3, 4]\n",
    "bc_indices = [5, 6, 7, 8]\n",
    "oc_indices = [9, 10, 11, 12]\n",
    "du_indices = [13, 14, 15, 16]\n",
    "\n",
    "# Define aerosol species and their corresponding indices\n",
    "species_indices = {\n",
    "    'so4': so4_indices,\n",
    "    'bc': bc_indices,\n",
    "    'oc': oc_indices,\n",
    "    'du': du_indices\n",
    "}\n",
    "\n",
    "# What are these indices?!\n",
    "extra_indices = [17, 18, 19, 20, 21, 22, 23] \n",
    "\n",
    "# Define aerosol species and their corresponding indices\n",
    "\n",
    "### ARGS ###\n",
    "args = add_nn_arguments_jupyter()\n",
    "# Overwrite the model name, keep everything else the same\n",
    "# Have one model for now as each input dim can be different\n",
    "args.model = 'transition_model'\n",
    "# args.model_id = 'transition_' + species # save different models\n",
    "# Run for only 3 epochs for proof of concept\n",
    "# Took around 2 mins per epoch\n",
    "args.epochs = 3 \n",
    "### DIFFERENT DIMS\n",
    "# Takes a minute\n",
    "# stats = calculate_stats(X_train, (y_train - X_train), X_test, (y_test - X_test), args)\n",
    "# y's can be delata and 24, X is raw\n",
    "stats = calculate_stats(X_train, y_delta_train_24, X_test, y_delta_test_24, args)\n",
    "\n",
    "# Look at stats\n",
    "np.set_printoptions(precision = 4, suppress = True, formatter = {'all': lambda x: f'{x:.4f}'})\n",
    "# stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species: so4 - TRAINING COMMENCED\n",
      "torch.Size([5713910, 5]) torch.Size([5713910, 5])\n",
      "GPU available: True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     45\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m     46\u001b[0m             model\u001b[38;5;241m.\u001b[39mparameters(), \n\u001b[1;32m     47\u001b[0m             lr \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mlr, \n\u001b[1;32m     48\u001b[0m             weight_decay \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mweight_decay)\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data_species\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# data loader\u001b[39;49;00m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid_data_species\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# validation\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# !!! Stats are used for the transforms\u001b[39;49;00m\n\u001b[1;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_valid_species\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#?? What is this used for \u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_valid_species\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#??\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Saves the model automatically\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m### LOAD trained model ###\u001b[39;00m\n\u001b[1;32m     64\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(\n\u001b[1;32m     65\u001b[0m     in_features \u001b[38;5;241m=\u001b[39m input_dim, out_features \u001b[38;5;241m=\u001b[39m output_dim, args \u001b[38;5;241m=\u001b[39m args, constraints_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# KB: constraints_active = True This is not used for the softmax model\u001b[39;00m\n\u001b[1;32m     67\u001b[0m ) \n",
      "File \u001b[0;32m~/massconserving_aerosols/utils.py:309\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, test_data, optimizer, input_dim, output_dim, X_test, y_test, stats, args)\u001b[0m\n\u001b[1;32m    307\u001b[0m     val_mse \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    308\u001b[0m     val_mass \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 309\u001b[0m     val_neg \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    311\u001b[0m     model_step(model, train_data, optimizer, i, args) \u001b[38;5;66;03m# model step takes train data\u001b[39;00m\n",
      "File \u001b[0;32m~/massconserving_aerosols/utils.py:338\u001b[0m, in \u001b[0;36mmodel_step\u001b[0;34m(model, train_data, optimizer, epoch, args)\u001b[0m\n\u001b[1;32m    336\u001b[0m # loss = r2(output, y) # use torch\n\u001b[1;32m    337\u001b[0m loss = get_loss(output, y, args) # rmse setting\n\u001b[0;32m--> 338\u001b[0m # print(\"loss check\")\n\u001b[1;32m    339\u001b[0m print(loss)\n\u001b[1;32m    340\u001b[0m loss.backward()\n",
      "File \u001b[0;32m~/anaconda3/envs/aero/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aero/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aero/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for species, indices in species_indices.items():\n",
    "    print(f\"Species: {species} - TRAINING COMMENCED\")\n",
    "\n",
    "    ### ARGS ###\n",
    "    args = add_nn_arguments_jupyter()\n",
    "    # Overwrite the model name, keep everything else the same\n",
    "    # Have one model for now as each input dim can be different\n",
    "    args.model = 'log_softmax' # Softmax model\n",
    "    args.model_id = 'logsoftmax_' + species # save different models\n",
    "    # Run for only 3 epochs for proof of concept\n",
    "    # Took around 2 mins per epoch\n",
    "    args.epochs = 1\n",
    "\n",
    "    # args.save_val_scores = True # For oversight\n",
    "    args.loss = 'rmse'\n",
    "\n",
    "    ### TRAIN ###\n",
    "    # Fetch the arrays using globals()\n",
    "    x_train_species = torch.tensor(X_train_24[:, indices], requires_grad = True, dtype = torch.float32)\n",
    "    y_train_species = torch.tensor(y_delta_train_24[:, indices], requires_grad = True, dtype = torch.float32)\n",
    "\n",
    "    x_valid_species = X_valid_24[:, indices]\n",
    "    y_valid_species = y_delta_valid_24[:, indices]\n",
    "\n",
    "    print(x_train_species.shape, y_train_species.shape)\n",
    "\n",
    "    input_dim = x_train_species.shape[1]\n",
    "    output_dim = y_train_species.shape[1]\n",
    "\n",
    "    # Create dataloaders: x, y\n",
    "    train_data_species = create_dataloader(x_train_species, y_train_species, args)\n",
    "    valid_data_species = create_test_dataloader(x_valid_species, y_valid_species, args)\n",
    "\n",
    "    # Initalize model\n",
    "    model = get_model(\n",
    "        in_features = input_dim, \n",
    "        out_features = output_dim, \n",
    "        args = args, \n",
    "        constraints_active = False)\n",
    "\n",
    "    if args.mode == 'train':\n",
    "            \n",
    "        optimizer = optim.Adam(\n",
    "                model.parameters(), \n",
    "                lr = args.lr, \n",
    "                weight_decay = args.weight_decay)\n",
    "\n",
    "        train_model(\n",
    "                model = model, \n",
    "                train_data = train_data_species, # data loader\n",
    "                test_data = valid_data_species, # validation\n",
    "                optimizer = optimizer, \n",
    "                input_dim = input_dim, \n",
    "                output_dim = output_dim, \n",
    "                stats = stats, # !!! Stats are used for the transforms\n",
    "                X_test = x_valid_species, #?? What is this used for \n",
    "                y_test = y_valid_species, #??\n",
    "                args = args)\n",
    "        # Saves the model automatically\n",
    "    \n",
    "    ### LOAD trained model ###\n",
    "    model = get_model(\n",
    "        in_features = input_dim, out_features = output_dim, args = args, constraints_active = True\n",
    "        # KB: constraints_active = True This is not used for the softmax model\n",
    "    ) \n",
    "\n",
    "    model.load_state_dict(torch.load('./models/' + args.model_id + '.pth') ['state_dict'])\n",
    "    model.to(device)\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch the test arrays using globals()\n",
    "    x_test_species = X_test_24[:, indices]\n",
    "    y_test_species = y_delta_test_24[:, indices]\n",
    "    y_test_species_absolute = y_test_24[:, indices]\n",
    "\n",
    "    # Model output is the tendency: rows of tendencies sum to zero as we just \"redistribute\" mass\n",
    "    y_test_species_tend_PRED = model(torch.tensor(x_test_species).to(device).float())\n",
    "    # Absolue Prediction. Project back using sums from x_test (not y_test itself)\n",
    "    y_test_species_absolute_PRED = y_test_species_tend_PRED + torch.tensor(x_test_species).to(device).float()\n",
    "\n",
    "    # sklearn function, same as np.square(relative_error).mean()\n",
    "    # relative is implicit in naming\n",
    "    MSE_tend = mean_squared_error(y_test_species, y_test_species_tend_PRED.detach().cpu().numpy())\n",
    "    R2_tend = r2_score(y_test_species, y_test_species_tend_PRED.detach().cpu().numpy())\n",
    "    print(f'Species: {species} | MSE tendency:', MSE_tend)\n",
    "    print(f'Species: {species} | R2 tendency:', R2_tend)\n",
    "\n",
    "    # true, pred\n",
    "    MSE_abs = mean_squared_error(y_test_species_absolute, y_test_species_absolute_PRED.detach().cpu().numpy())\n",
    "    R2_abs = r2_score(y_test_species_absolute, y_test_species_absolute_PRED.detach().cpu().numpy())\n",
    "    print(f'Species: {species} | MSE absolute:', MSE_abs)\n",
    "    print(f'Species: {species} | R2 absolute:', R2_abs)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kim/massconserving_aerosols/models.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_log = torch.clamp(torch.tensor(x), min = 1e-8)  # Apply log transformation to the input\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
       "        [-3.0933e-04,  1.2373e-03, -3.0933e-04, -3.0933e-04, -3.0933e-04],\n",
       "        [-5.3107e-04,  2.1243e-03, -5.3107e-04, -5.3107e-04, -5.3107e-04],\n",
       "        [-7.7238e-05,  3.0895e-04, -7.7238e-05, -7.7238e-05, -7.7238e-05],\n",
       "        [-1.1300e-04,  4.5202e-04, -1.1300e-04, -1.1300e-04, -1.1300e-04],\n",
       "        [-1.4257e-01,  5.7027e-01, -1.4257e-01, -1.4257e-01, -1.4257e-01],\n",
       "        [-0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_so4_subset = X_train_24[np.ix_([-4, 0, 1000, 20000, 21000, 400000, -1], so4_indices)]\n",
    "y_train_so4_subset = y_train_24[np.ix_([-4, 0, 1000, 20000, 21000, 400000, -1], so4_indices)]\n",
    "y_delta_train_so4_subset = y_delta_train_24[np.ix_([-4, 0, 1000, 20000, 21000, 400000, -1], so4_indices)]\n",
    "\n",
    "input = torch.tensor(x_train_so4_subset, dtype = torch.float32).to(device)\n",
    "# force issues: input = input - input *0.9999\n",
    "out = model(input)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: \n",
    "\n",
    "- cheaper to transform data once outside of function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
