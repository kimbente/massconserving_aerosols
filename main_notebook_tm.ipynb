{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload module is not an IPython extension.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%autoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description : Train neural network model to predict one time step of M7\n",
    "Options:\n",
    "\n",
    "  --signs=<need_extra_signs_for_log_mass>\n",
    "  --classification=<train_classification_net>\n",
    "  --scale=<scaler>\n",
    "  --model=<model_version>\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from utils import standard_transform_x, standard_transform_y, get_model, train_model, create_report, calculate_stats, log_full_norm_transform_x, log_tend_norm_transform_y, create_dataloader, create_test_dataloader\n",
    "# from models import Softmax_model\n",
    "from utils import add_nn_arguments_jupyter\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# KB add for active development in models or utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5713910,28) (5713910,32) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m args\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Takes a minute\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m stats \u001b[38;5;241m=\u001b[39m calculate_stats(X_train, (\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m), X_test, (y_test \u001b[38;5;241m-\u001b[39m X_train), args)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Look at stats\u001b[39;00m\n\u001b[1;32m     51\u001b[0m np\u001b[38;5;241m.\u001b[39mset_printoptions(precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, suppress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, formatter \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5713910,28) (5713910,32) "
     ]
    }
   ],
   "source": [
    "# define full path \n",
    "path_to_data = \"/home/kim/data/aerosols/aerosol_emulation_data/\"\n",
    "\n",
    "X_test = np.load(path_to_data + 'X_test.npy')\n",
    "y_test = np.load(path_to_data + 'y_test.npy')\n",
    "\n",
    "X_train = np.load(path_to_data + 'X_train.npy')\n",
    "y_train = np.load(path_to_data + 'y_train.npy')\n",
    "\n",
    "X_valid = np.load(path_to_data + 'X_val.npy')\n",
    "y_valid = np.load(path_to_data + 'y_val.npy')\n",
    "\n",
    "# Select the correct 24 columns\n",
    "X_test_24 = X_test[:, 8:]\n",
    "X_train_24 = X_train[:, 8:] \n",
    "\n",
    "y_test_24 = y_test[:, :24]\n",
    "y_train_24 = y_train[:, :24]\n",
    "\n",
    "y_valid_24 = y_valid[:, :24]\n",
    "X_valid_24 = X_valid[:, 8:]\n",
    "\n",
    "# How much has it changes between x (at t = 0)  and y (at t = 1)\n",
    "y_delta_train_24 = y_train_24 - X_train_24\n",
    "y_delta_test_24 = y_test_24 - X_test_24\n",
    "y_delta_valid_24 = y_valid_24 - X_valid_24\n",
    "\n",
    "# Define column indices for each of the components (24 column version)\n",
    "so4_indices = [0, 1, 2, 3, 4]\n",
    "bc_indices = [5, 6, 7, 8]\n",
    "oc_indices = [9, 10, 11, 12]\n",
    "du_indices = [13, 14, 15, 16]\n",
    "\n",
    "# What are these indices?!\n",
    "extra_indices = [17, 18, 19, 20, 21, 22, 23] \n",
    "\n",
    "### ARGS ###\n",
    "args = add_nn_arguments_jupyter()\n",
    "# Overwrite the model name, keep everything else the same\n",
    "# Have one model for now as each input dim can be different\n",
    "args.model = 'transition_model'\n",
    "args.model_id = 'transition_' + species # save different models\n",
    "# Run for only 3 epochs for proof of concept\n",
    "# Took around 2 mins per epoch\n",
    "args.epochs = 3 \n",
    "\n",
    "# Takes a minute\n",
    "stats = calculate_stats(X_train, (y_train - X_train), X_test, (y_test - X_train), args)\n",
    "\n",
    "# Look at stats\n",
    "np.set_printoptions(precision = 4, suppress = True, formatter = {'all': lambda x: f'{x:.4f}'})\n",
    "# stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionMM(nn.Module):\n",
    "    def __init__(self, in_features, out_features, width, depth = 2):\n",
    "        super(TransitionMM, self).__init__()\n",
    "        self.out_features = out_features\n",
    "        self.fc_in = nn.Linear(in_features = in_features, out_features = width)\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(depth -1):\n",
    "            self.hidden_layers.append(nn.ReLU())\n",
    "            self.hidden_layers.append(nn.Linear(in_features = width, out_features = width))\n",
    "            self.hidden_layers.append(nn.ReLU())\n",
    "        # square output\n",
    "        self.fc_out = nn.Linear(in_features = width, out_features = out_features * out_features) # square output\n",
    "    def forward(self, x):\n",
    "        state = self.fc_in(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            state = layer(state)\n",
    "        state = self.fc_out(state)\n",
    "        state = state.view(-1, self.out_features, self.out_features)\n",
    "        tm = F.softmax(state, dim = 1)  # Apply softmax across each columns to that columns (last dim) add to 1\n",
    "        # tm is shape(batch_size, out_features, out_features)\n",
    "        # x is shape(batch_size, in_features)\n",
    "        out = torch.bmm(tm, x.unsqueeze(-1)).squeeze(-1)\n",
    "        # predict the delta (tendencies)\n",
    "        y_delta = out - x\n",
    "        return y_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train_24[0:7, so4_indices]\n",
    "y_train = y_train_24[0:7, so4_indices]\n",
    "\n",
    "model = TransitionMM(in_features = x_train.shape[1], out_features = y_train.shape[1], width = 128, depth = 2)\n",
    "print(model(torch.tensor(x_train).to(torch.float32)).sum(1))\n",
    "\n",
    "print(torch.tensor(x_train).to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define aerosol species and their corresponding indices\n",
    "species_indices = {\n",
    "    'so4': so4_indices,\n",
    "    'bc': bc_indices,\n",
    "    'oc': oc_indices,\n",
    "    'du': du_indices\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species: so4 - TRAINING COMMENCED\n",
      "(5713910, 5) (5713910, 5)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 54\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     42\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m     43\u001b[0m             model\u001b[38;5;241m.\u001b[39mparameters(), \n\u001b[1;32m     44\u001b[0m             lr \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mlr, \n\u001b[1;32m     45\u001b[0m             weight_decay \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mweight_decay)\n\u001b[1;32m     47\u001b[0m     train_model(\n\u001b[1;32m     48\u001b[0m             model \u001b[38;5;241m=\u001b[39m model, \n\u001b[1;32m     49\u001b[0m             train_data \u001b[38;5;241m=\u001b[39m train_data_species, \n\u001b[1;32m     50\u001b[0m             test_data \u001b[38;5;241m=\u001b[39m valid_data_species, \u001b[38;5;66;03m# validation\u001b[39;00m\n\u001b[1;32m     51\u001b[0m             optimizer \u001b[38;5;241m=\u001b[39m optimizer, \n\u001b[1;32m     52\u001b[0m             input_dim \u001b[38;5;241m=\u001b[39m input_dim, \n\u001b[1;32m     53\u001b[0m             output_dim \u001b[38;5;241m=\u001b[39m output_dim, \n\u001b[0;32m---> 54\u001b[0m             stats \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m, \n\u001b[1;32m     55\u001b[0m             X_test \u001b[38;5;241m=\u001b[39m X_test, \u001b[38;5;66;03m#??\u001b[39;00m\n\u001b[1;32m     56\u001b[0m             y_test \u001b[38;5;241m=\u001b[39m y_test, \u001b[38;5;66;03m#??\u001b[39;00m\n\u001b[1;32m     57\u001b[0m             args \u001b[38;5;241m=\u001b[39m args)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# Saves the model automatically\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m### LOAD trained model ###\u001b[39;00m\n\u001b[1;32m     61\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(\n\u001b[1;32m     62\u001b[0m     in_features \u001b[38;5;241m=\u001b[39m input_dim, out_features \u001b[38;5;241m=\u001b[39m output_dim, args \u001b[38;5;241m=\u001b[39m args, constraints_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# KB: constraints_active = True This is not used for the softmax model\u001b[39;00m\n\u001b[1;32m     64\u001b[0m ) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for species, indices in species_indices.items():\n",
    "    print(f\"Species: {species} - TRAINING COMMENCED\")\n",
    "\n",
    "    ### ARGS ###\n",
    "    args = add_nn_arguments_jupyter()\n",
    "    # Overwrite the model name, keep everything else the same\n",
    "    # Have one model for now as each input dim can be different\n",
    "    args.model = 'transition_model'\n",
    "    args.model_id = 'transition_' + species # save different models\n",
    "    # Run for only 3 epochs for proof of concept\n",
    "    # Took around 2 mins per epoch\n",
    "    args.epochs = 3 \n",
    "\n",
    "    ### TRAIN ###\n",
    "    # Fetch the arrays using globals()\n",
    "    x_train_species = X_train_24[:, indices]\n",
    "    y_train_species = y_delta_train_24[:, indices]\n",
    "\n",
    "    x_valid_species = X_valid_24[:, indices]\n",
    "    y_valid_species = y_delta_valid_24[:, indices]\n",
    "\n",
    "    print(x_train_species.shape, y_train_species.shape)\n",
    "\n",
    "    input_dim = x_train_species.shape[1]\n",
    "    output_dim = y_train_species.shape[1]\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_data_species = create_dataloader(x_train_species, y_train_species, args)\n",
    "    valid_data_species = create_test_dataloader(x_valid_species, y_valid_species, args)\n",
    "\n",
    "    # Initalize model\n",
    "    model = get_model(\n",
    "        in_features = input_dim, \n",
    "        out_features = output_dim, \n",
    "        args = args, \n",
    "        constraints_active = False)\n",
    "\n",
    "    if args.mode == 'train':\n",
    "            \n",
    "        optimizer = optim.Adam(\n",
    "                model.parameters(), \n",
    "                lr = args.lr, \n",
    "                weight_decay = args.weight_decay)\n",
    "\n",
    "        train_model(\n",
    "                model = model, \n",
    "                train_data = train_data_species, \n",
    "                test_data = valid_data_species, # validation\n",
    "                optimizer = optimizer, \n",
    "                input_dim = input_dim, \n",
    "                output_dim = output_dim, \n",
    "                stats = stats, \n",
    "                X_test = X_test, #??\n",
    "                y_test = y_test, #??\n",
    "                args = args)\n",
    "        # Saves the model automatically\n",
    "    \n",
    "    ### LOAD trained model ###\n",
    "    model = get_model(\n",
    "        in_features = input_dim, out_features = output_dim, args = args, constraints_active = True\n",
    "        # KB: constraints_active = True This is not used for the softmax model\n",
    "    ) \n",
    "    model.load_state_dict(torch.load('./models/' + args.model_id + '.pth') ['state_dict'])\n",
    "    model.to(device)\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch the test arrays using globals()\n",
    "    x_test_species = X_test_24[:, indices]\n",
    "    y_test_species = y_delta_test_24[:, indices]\n",
    "    y_test_species_absolute = y_test_24[:, indices]\n",
    "\n",
    "    # Model output is the tendency\n",
    "    y_test_species_tend_PRED = model(torch.tensor(x_test_species).to(device).float())\n",
    "    # Absolue Prediction. Project back using sums from x_test (not y_test itself)\n",
    "    y_test_species_absolute_PRED = y_test_species_tend_PRED + torch.tensor(x_test_species).to(device).float()\n",
    "\n",
    "    # sklearn function, same as np.square(relative_error).mean()\n",
    "    # relative is implicit in naming\n",
    "    MSE_tend = mean_squared_error(y_test_species, y_test_species_tend_PRED.detach().cpu().numpy())\n",
    "    R2_tend = r2_score(y_test_species, y_test_species_tend_PRED.detach().cpu().numpy())\n",
    "    print(f'Species: {species} | MSE tendency:', MSE_tend)\n",
    "    print(f'Species: {species} | R2 tendency:', R2_tend)\n",
    "\n",
    "    # true, pred\n",
    "    MSE_abs = mean_squared_error(y_test_species_absolute, y_test_species_absolute_PRED)\n",
    "    R2_abs = r2_score(y_test_species_absolute, y_test_species_absolute_PRED)\n",
    "    print(f'Species: {species} | MSE absolute:', MSE_abs)\n",
    "    print(f'Species: {species} | R2 absolute:', R2_abs)\n",
    "\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_24[:, indices]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
