{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload module is not an IPython extension.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%autoreload` not found.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Description : Train neural network model to predict one time step of M7\n",
    "Options:\n",
    "\n",
    "  --signs=<need_extra_signs_for_log_mass>\n",
    "  --classification=<train_classification_net>\n",
    "  --scale=<scaler>\n",
    "  --model=<model_version>\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from utils import standard_transform_x, standard_transform_y, get_model, train_model, create_report, calculate_stats, log_full_norm_transform_x, log_tend_norm_transform_y, create_dataloader, create_test_dataloader\n",
    "# from models import Softmax_model\n",
    "from utils import add_nn_arguments_jupyter\n",
    "import torch.nn as nn \n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# KB add for active development in models or utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define full path \n",
    "path_to_data = \"/home/kim/data/aerosols/aerosol_emulation_data/\"\n",
    "\n",
    "X_test = np.load(path_to_data + 'X_test.npy')\n",
    "y_test = np.load(path_to_data + 'y_test.npy')\n",
    "\n",
    "X_train = np.load(path_to_data + 'X_train.npy')\n",
    "y_train = np.load(path_to_data + 'y_train.npy')\n",
    "\n",
    "X_valid = np.load(path_to_data + 'X_val.npy')\n",
    "y_valid = np.load(path_to_data + 'y_val.npy')\n",
    "\n",
    "# Select the correct 24 columns\n",
    "X_test_24 = X_test[:, 8:]\n",
    "X_train_24 = X_train[:, 8:] \n",
    "\n",
    "y_test_24 = y_test[:, :24]\n",
    "y_train_24 = y_train[:, :24]\n",
    "\n",
    "y_valid_24 = y_valid[:, :24]\n",
    "X_valid_24 = X_valid[:, 8:]\n",
    "\n",
    "# How much has it changes between x (at t = 0)  and y (at t = 1)\n",
    "y_delta_train_24 = y_train_24 - X_train_24\n",
    "y_delta_test_24 = y_test_24 - X_test_24\n",
    "y_delta_valid_24 = y_valid_24 - X_valid_24\n",
    "\n",
    "# Define column indices for each of the components (24 column version)\n",
    "so4_indices = [0, 1, 2, 3, 4]\n",
    "bc_indices = [5, 6, 7, 8]\n",
    "oc_indices = [9, 10, 11, 12]\n",
    "du_indices = [13, 14, 15, 16]\n",
    "\n",
    "# Define aerosol species and their corresponding indices\n",
    "species_indices = {\n",
    "    'so4': so4_indices,\n",
    "    'bc': bc_indices,\n",
    "    'oc': oc_indices,\n",
    "    'du': du_indices\n",
    "}\n",
    "\n",
    "# What are these indices?!\n",
    "extra_indices = [17, 18, 19, 20, 21, 22, 23] \n",
    "\n",
    "# Define aerosol species and their corresponding indices\n",
    "\n",
    "### ARGS ###\n",
    "args = add_nn_arguments_jupyter()\n",
    "# Overwrite the model name, keep everything else the same\n",
    "# Have one model for now as each input dim can be different\n",
    "args.model = 'transition_model'\n",
    "# args.model_id = 'transition_' + species # save different models\n",
    "# Run for only 3 epochs for proof of concept\n",
    "# Took around 2 mins per epoch\n",
    "args.epochs = 3 \n",
    "### DIFFERENT DIMS\n",
    "# Takes a minute\n",
    "# stats = calculate_stats(X_train, (y_train - X_train), X_test, (y_test - X_test), args)\n",
    "# y's can be delata and 24, X is raw\n",
    "stats = calculate_stats(X_train, y_delta_train_24, X_test, y_delta_test_24, args)\n",
    "\n",
    "# Look at stats\n",
    "np.set_printoptions(precision = 4, suppress = True, formatter = {'all': lambda x: f'{x:.4f}'})\n",
    "# stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0035, dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_so4 = X_train_24[0:7, so4_indices]\n",
    "y_train_so4 = y_train_24[0:7, so4_indices]\n",
    "y_delta_train_so4 = y_delta_train_24[0:7, so4_indices]\n",
    "\n",
    "# What would the train loss be if we only predict zeros\n",
    "criterion = nn.MSELoss()\n",
    "criterion(torch.tensor(y_delta_train_so4), torch.zeros(y_delta_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(mode='train', signs=False, scale='z', model='standard', model_id='standard_test', log=False, lr=0.001, width=128, depth=2, loss='mse', optimizer='adam', weight_decay=1e-09, batch_size=256, epochs=100, early_stop=False, save_val_scores=False, old_data=False)\n"
     ]
    }
   ],
   "source": [
    "args = add_nn_arguments_jupyter()\n",
    "print(args)\n",
    "\n",
    "args.save_val_scores = True # For oversight\n",
    "args.scale = 'log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species: so4 - TRAINING COMMENCED\n",
      "(5713910, 5) (5713910, 5)\n",
      "GPU available: True\n",
      "Epoch 1, Train Loss: 13356522662216159232.00000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 50\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     45\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m     46\u001b[0m             model\u001b[38;5;241m.\u001b[39mparameters(), \n\u001b[1;32m     47\u001b[0m             lr \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mlr, \n\u001b[1;32m     48\u001b[0m             weight_decay \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mweight_decay)\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data_species\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# data loader\u001b[39;49;00m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid_data_species\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# validation\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# !!! Stats are used for the transforms\u001b[39;49;00m\n\u001b[1;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_valid_species\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#??\u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_valid_species\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#??\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Saves the model automatically\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m### LOAD trained model ###\u001b[39;00m\n\u001b[1;32m     64\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(\n\u001b[1;32m     65\u001b[0m     in_features \u001b[38;5;241m=\u001b[39m input_dim, out_features \u001b[38;5;241m=\u001b[39m output_dim, args \u001b[38;5;241m=\u001b[39m args, constraints_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# KB: constraints_active = True This is not used for the softmax model\u001b[39;00m\n\u001b[1;32m     67\u001b[0m ) \n",
      "File \u001b[0;32m~/massconserving_aerosols/utils.py:306\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, test_data, optimizer, input_dim, output_dim, X_test, y_test, stats, args)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    305\u001b[0m     model_step(model, train_data, optimizer, i, args)\n\u001b[0;32m--> 306\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_val_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39msave_val_scores:\n\u001b[1;32m    308\u001b[0m         r2, mse, mass, neg \u001b[38;5;241m=\u001b[39m get_val_scores(model, X_test, y_test, i, stats, args)\n",
      "File \u001b[0;32m~/massconserving_aerosols/utils.py:341\u001b[0m, in \u001b[0;36mget_val_loss\u001b[0;34m(model, test_data, epoch, args)\u001b[0m\n\u001b[1;32m    338\u001b[0m     loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_data)\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, loss))\n\u001b[0;32m--> 341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_val_loss\u001b[39m(model, test_data, epoch, args):\n\u001b[1;32m    342\u001b[0m     running_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    343\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/aero/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/aero/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/aero/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/aero/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/aero/lib/python3.10/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/aero/lib/python3.10/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:2017\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/aero/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_is_thread_alive.py:16\u001b[0m, in \u001b[0;36mis_thread_alive\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39m_handle\u001b[38;5;241m.\u001b[39mis_done()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_temp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_stopped\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# Python 3.12 and earlier has this\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_thread_alive\u001b[39m(t):\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39m_is_stopped\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_temp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Thread__stopped\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# Python 2.x has this\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for species, indices in species_indices.items():\n",
    "    print(f\"Species: {species} - TRAINING COMMENCED\")\n",
    "\n",
    "    ### ARGS ###\n",
    "    args = add_nn_arguments_jupyter()\n",
    "    # Overwrite the model name, keep everything else the same\n",
    "    # Have one model for now as each input dim can be different\n",
    "    args.model = 'transition_model'\n",
    "    args.model_id = 'transition_' + species # save different models\n",
    "    # Run for only 3 epochs for proof of concept\n",
    "    # Took around 2 mins per epoch\n",
    "    args.epochs = 2\n",
    "\n",
    "    args.save_val_scores = True # For oversight\n",
    "    args.loss = 'mse'\n",
    "\n",
    "    ### TRAIN ###\n",
    "    # Fetch the arrays using globals()\n",
    "    x_train_species = X_train_24[:, indices]\n",
    "    y_train_species = y_delta_train_24[:, indices]\n",
    "\n",
    "    x_valid_species = X_valid_24[:, indices]\n",
    "    y_valid_species = y_delta_valid_24[:, indices]\n",
    "\n",
    "    print(x_train_species.shape, y_train_species.shape)\n",
    "\n",
    "    input_dim = x_train_species.shape[1]\n",
    "    output_dim = y_train_species.shape[1]\n",
    "\n",
    "    # Create dataloaders: x, y\n",
    "    train_data_species = create_dataloader(x_train_species, y_train_species, args)\n",
    "    valid_data_species = create_test_dataloader(x_valid_species, y_valid_species, args)\n",
    "\n",
    "    # Initalize model\n",
    "    model = get_model(\n",
    "        in_features = input_dim, \n",
    "        out_features = output_dim, \n",
    "        args = args, \n",
    "        constraints_active = False)\n",
    "\n",
    "    if args.mode == 'train':\n",
    "            \n",
    "        optimizer = optim.Adam(\n",
    "                model.parameters(), \n",
    "                lr = args.lr, \n",
    "                weight_decay = args.weight_decay)\n",
    "\n",
    "        train_model(\n",
    "                model = model, \n",
    "                train_data = train_data_species, # data loader\n",
    "                test_data = valid_data_species, # validation\n",
    "                optimizer = optimizer, \n",
    "                input_dim = input_dim, \n",
    "                output_dim = output_dim, \n",
    "                stats = stats, # !!! Stats are used for the transforms\n",
    "                X_test = x_valid_species, #??\n",
    "                y_test = y_valid_species, #??\n",
    "                args = args)\n",
    "        # Saves the model automatically\n",
    "    \n",
    "    ### LOAD trained model ###\n",
    "    model = get_model(\n",
    "        in_features = input_dim, out_features = output_dim, args = args, constraints_active = True\n",
    "        # KB: constraints_active = True This is not used for the softmax model\n",
    "    ) \n",
    "    model.load_state_dict(torch.load('./models/' + args.model_id + '.pth') ['state_dict'])\n",
    "    model.to(device)\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "\n",
    "    # Fetch the test arrays using globals()\n",
    "    x_test_species = X_test_24[:, indices]\n",
    "    y_test_species = y_delta_test_24[:, indices]\n",
    "    y_test_species_absolute = y_test_24[:, indices]\n",
    "\n",
    "    # Model output is the tendency\n",
    "    y_test_species_tend_PRED = model(torch.tensor(x_test_species).to(device).float())\n",
    "    # Absolue Prediction. Project back using sums from x_test (not y_test itself)\n",
    "    y_test_species_absolute_PRED = y_test_species_tend_PRED + torch.tensor(x_test_species).to(device).float()\n",
    "\n",
    "    # sklearn function, same as np.square(relative_error).mean()\n",
    "    # relative is implicit in naming\n",
    "    MSE_tend = mean_squared_error(y_test_species, y_test_species_tend_PRED.detach().cpu().numpy())\n",
    "    R2_tend = r2_score(y_test_species, y_test_species_tend_PRED.detach().cpu().numpy())\n",
    "    print(f'Species: {species} | MSE tendency:', MSE_tend)\n",
    "    print(f'Species: {species} | R2 tendency:', R2_tend)\n",
    "\n",
    "    # true, pred\n",
    "    MSE_abs = mean_squared_error(y_test_species_absolute, y_test_species_absolute_PRED.detach().cpu().numpy())\n",
    "    R2_abs = r2_score(y_test_species_absolute, y_test_species_absolute_PRED.detach().cpu().numpy())\n",
    "    print(f'Species: {species} | MSE absolute:', MSE_abs)\n",
    "    print(f'Species: {species} | R2 absolute:', R2_abs)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation issue\n",
    "\n",
    "Uses standard_transform_y_inv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
