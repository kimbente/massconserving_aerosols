{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "76c1f637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'arcsinh_train_species' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspecies\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_arcsinh_unitvar\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m arcsinh_unitvar_split_species\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Call\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m \u001b[43marcsinh_x_per_species\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21marcsin_y_delta_per_species\u001b[39m(eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# Iterate over species\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m species, indices \u001b[38;5;129;01min\u001b[39;00m species_indices\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;66;03m# Iterate over data splits (train, val, test)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[93], line 93\u001b[0m, in \u001b[0;36marcsinh_x_per_species\u001b[0;34m(eps)\u001b[0m\n\u001b[1;32m     89\u001b[0m arcsinh_split_species \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marcsinh(nonneg_split_species)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# STEP 3: Scale to unit variance i.e. unit std\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m species_std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstd(\u001b[43marcsinh_train_species\u001b[49m)\n\u001b[1;32m     94\u001b[0m arcsinh_unitvar_split_species \u001b[38;5;241m=\u001b[39m arcsinh_split_species \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mstd(arcsinh_split_species)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# globals()[f'x_{split}_{species}_arcsinh_unitvar'] = arcsinh_split_species_unitvar\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# SAVE\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arcsinh_train_species' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torcheval.metrics.functional import r2_score as r2\n",
    "import sklearn\n",
    "\n",
    "### GPU ###\n",
    "# I have majority access to GPU on afternoons on even days, and mornings on odd days\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "### DATA ###\n",
    "# define full path \n",
    "path_to_data = \"/home/kim/data/aerosols/aerosol_emulation_data/\"\n",
    "\n",
    "# NP for now\n",
    "x_train = np.load(path_to_data + 'X_train.npy')\n",
    "y_train = np.load(path_to_data + 'y_train.npy')\n",
    "\n",
    "x_test = np.load(path_to_data + 'X_test.npy')\n",
    "y_test = np.load(path_to_data + 'y_test.npy')\n",
    "\n",
    "x_val = np.load(path_to_data + 'X_val.npy')\n",
    "y_val = np.load(path_to_data + 'y_val.npy')\n",
    "\n",
    "# Select the correct 24 columns\n",
    "# x train, val, test\n",
    "x_train_24 = x_train[:, 8:]\n",
    "x_val_24 = x_val[:, 8:]\n",
    "x_test_24 = x_test[:, 8:]\n",
    "\n",
    "# y train, val, test\n",
    "y_train_24 = y_train[:, :24]\n",
    "y_val_24 = y_val[:, :24]\n",
    "y_test_24 = y_test[:, :24]\n",
    "\n",
    "# How much has it changes between x (at t = 0)  and y (at t = 1)\n",
    "y_delta_train_24 = y_train_24 - x_train_24\n",
    "y_delta_val_24 = y_val_24 - x_val_24\n",
    "y_delta_test_24 = y_test_24 - x_test_24\n",
    "\n",
    "### SPECIES ###\n",
    "# Define column indices for each of the components (24 column version)\n",
    "so4_indices = [0, 1, 2, 3, 4]\n",
    "bc_indices = [5, 6, 7, 8]\n",
    "oc_indices = [9, 10, 11, 12]\n",
    "du_indices = [13, 14, 15, 16]\n",
    "\n",
    "# Define aerosol species and their corresponding indices\n",
    "species_indices = {\n",
    "    'so4': so4_indices,\n",
    "    'bc': bc_indices,\n",
    "    'oc': oc_indices,\n",
    "    'du': du_indices\n",
    "}\n",
    "\n",
    "### SPLIT ###\n",
    "data_split = ['train', 'val', 'test']\n",
    "\n",
    "# What are these indices?!\n",
    "extra_indices = [17, 18, 19, 20, 21, 22, 23] \n",
    "\n",
    "##########################\n",
    "### Normalise the data ###\n",
    "##########################\n",
    "\n",
    "def arcsinh_x_per_species(eps = 1e-5):\n",
    "    # This transformation can be easily reversed and preserved the zero\n",
    "    # Iterate over species\n",
    "    # We arcsinh (universal) and normalise by species variance\n",
    "    for species, indices in species_indices.items():\n",
    "        # Iterate over data splits (train, val, test)\n",
    "        for split in data_split:\n",
    "            # Fetch the data\n",
    "            x_split_species = globals()[f'x_{split}_24'][:, indices]\n",
    "            # Make tensor\n",
    "            x_split_species = torch.tensor(x_split_species).clone()\n",
    "\n",
    "            # STEP 1: Clamp negative values as these should not be allowed\n",
    "            nonneg_split_species = torch.clamp_min(x_split_species, min = 0.0)\n",
    "\n",
    "            # STEP 2: Arcsinh\n",
    "            arcsinh_split_species = torch.arcsinh(nonneg_split_species)\n",
    "\n",
    "            # STEP 3: Scale to unit variance i.e. unit std\n",
    "            # \n",
    "            species_std = torch.std(arcsinh_train_species)\n",
    "            arcsinh_unitvar_split_species = arcsinh_split_species / torch.std(arcsinh_split_species)\n",
    "            # globals()[f'x_{split}_{species}_arcsinh_unitvar'] = arcsinh_split_species_unitvar\n",
    "\n",
    "            # SAVE\n",
    "            globals()[f'x_{split}_{species}'] = x_split_species\n",
    "            globals()[f'x_{split}_{species}_arcsinh'] = arcsinh_split_species\n",
    "            # option\n",
    "            globals()[f'x_{split}_{species}_arcsinh_unitvar'] = arcsinh_unitvar_split_species\n",
    "\n",
    "# Call\n",
    "arcsinh_x_per_species()\n",
    "\n",
    "def arcsin_y_delta_per_species(eps = 1e-5):\n",
    "    # Iterate over species\n",
    "    for species, indices in species_indices.items():\n",
    "        # Iterate over data splits (train, val, test)\n",
    "        for split in data_split:\n",
    "            # Fetch the data\n",
    "            y_delta_split_species = globals()[f'y_delta_{split}_24'][:, indices]\n",
    "            # Make tensor\n",
    "            y_delta_split_species = torch.tensor(y_delta_split_species).clone()\n",
    "            # We use this variable for og domain comparison\n",
    "            globals()[f'y_delta_{split}_{species}'] = y_delta_split_species\n",
    "\n",
    "            # STEP 1: scale to unit var\n",
    "            # Maybe we should not have access to this\n",
    "            y_delta_split_species_unitvar = y_delta_split_species / torch.std(y_delta_split_species)\n",
    "            # globals()[f'y_delta_{split}_{species}_unitvar'] = y_delta_split_species_unitvar\n",
    "\n",
    "            # export std to global namespace for renormalization\n",
    "            globals()[f'std_y_delta_{split}_{species}'] = torch.std(y_delta_split_species)\n",
    "\n",
    "            # STEP 2: Arcsin\n",
    "            arcsinh_y_delta_split_species = torch.asinh(y_delta_split_species)\n",
    "            arcsinh_unitvar_y_delta_split_species = torch.asinh(y_delta_split_species_unitvar)\n",
    "\n",
    "            # SAVE both options\n",
    "            globals()[f'y_delta_{split}_{species}_arcsinh'] = arcsinh_y_delta_split_species\n",
    "            globals()[f'y_delta_{split}_{species}_arcsinh_unitvar'] = arcsinh_unitvar_y_delta_split_species\n",
    "\n",
    "# Call\n",
    "arcsin_y_delta_per_species()\n",
    "\n",
    "# no transformation, just export in same manner\n",
    "def y_per_species():\n",
    "    for species, indices in species_indices.items():\n",
    "        # Iterate over data splits (train, val, test)\n",
    "        for split in data_split:\n",
    "            # Fetch the data\n",
    "            y_split_species = globals()[f'y_{split}_24'][:, indices]\n",
    "            globals()[f'y_{split}_{species}'] = torch.tensor(y_split_species)\n",
    "\n",
    "# Call\n",
    "y_per_species()\n",
    "\n",
    "# Helper\n",
    "def n_random_row_incides(x, n = 5000):\n",
    "    \"\"\"Returns n random rows from x\"\"\"\n",
    "    # Default is 5000\n",
    "    indices = np.random.choice(x.shape[0], n, replace = False)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "849b41d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(198166)\n"
     ]
    }
   ],
   "source": [
    "# 5 mil rows\n",
    "num_negative_rows = (torch.tensor(x_train) < 0).any(dim = 1).sum()\n",
    "print(num_negative_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de492f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0021],\n",
       "        [0.0021, 1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we are predicting this ratio\n",
    "a = ratio_train_so4.flatten().unsqueeze(0)\n",
    "b = x_train_so4_arcsinh_unitvar.flatten().unsqueeze(0)\n",
    "# same as x_train_so4_arcsinh.flatten().unsqueeze(0)\n",
    "\n",
    "corr_input = torch.cat((a, b), dim = 0)\n",
    "\n",
    "torch.corrcoef(corr_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f46678df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1957e+08, dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio_train_so4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fea26bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f192492d240>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_indices = n_random_row_incides(x_train_so4, n = 5000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(ratio_train_so4[random_indices], y_train_so4[random_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa2cf0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2ee2c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torcheval.metrics.functional import r2_score as r2\n",
    "\n",
    "### GPU ###\n",
    "# I have majority access to GPU on afternoons on even days, and mornings on odd days\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "### DATA ###\n",
    "# define full path \n",
    "path_to_data = \"/home/kim/data/aerosols/aerosol_emulation_data/\"\n",
    "\n",
    "# Load and make torch tensors\n",
    "# Select the correct 24 columns\n",
    "x_train = torch.tensor(np.load(path_to_data + 'X_train.npy'))[:, 8:]\n",
    "y_train = torch.tensor(np.load(path_to_data + 'y_train.npy'))[:, :24]\n",
    "\n",
    "x_test = torch.tensor(np.load(path_to_data + 'X_test.npy'))[:, 8:]\n",
    "y_test = torch.tensor(np.load(path_to_data + 'y_test.npy'))[:, :24]\n",
    "\n",
    "x_val = torch.tensor(np.load(path_to_data + 'X_val.npy'))[:, 8:]\n",
    "y_val = torch.tensor(np.load(path_to_data + 'y_val.npy'))[:, :24]\n",
    "\n",
    "### SPECIES ###\n",
    "# Define column indices for each of the components (24 column version)\n",
    "so4_indices = [0, 1, 2, 3, 4]\n",
    "bc_indices = [5, 6, 7, 8]\n",
    "oc_indices = [9, 10, 11, 12]\n",
    "du_indices = [13, 14, 15, 16]\n",
    "\n",
    "# Define aerosol species and their corresponding indices\n",
    "species_indices = {\n",
    "    'so4': so4_indices,\n",
    "    'bc': bc_indices,\n",
    "    'oc': oc_indices,\n",
    "    'du': du_indices\n",
    "}\n",
    "\n",
    "### SPLIT ###\n",
    "data_split = ['train', 'val', 'test']\n",
    "\n",
    "# What are these indices?!\n",
    "extra_indices = [17, 18, 19, 20, 21, 22, 23] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87833b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5713910, 29])\n",
      "torch.Size([5713910, 28])\n",
      "torch.Size([5713910, 28])\n",
      "torch.Size([5713910, 28])\n",
      "torch.Size([2856955, 29])\n",
      "torch.Size([2856955, 28])\n",
      "torch.Size([2856955, 28])\n",
      "torch.Size([2856955, 28])\n",
      "torch.Size([2856955, 29])\n",
      "torch.Size([2856955, 28])\n",
      "torch.Size([2856955, 28])\n",
      "torch.Size([2856955, 28])\n"
     ]
    }
   ],
   "source": [
    "def preprocess_x(eps = 1e-5):\n",
    "    # STEP 1:\n",
    "    # Define global normalising constant taken from TRAIN (largest dataset)\n",
    "    for species, indices in species_indices.items():\n",
    "            x_train_species_arcsinh_std = torch.arcsinh(x_train[:, indices]).std()\n",
    "            globals()[f\"arcsinh_std_x_{species}\"] = x_train_species_arcsinh_std\n",
    "\n",
    "    for split in data_split:\n",
    "\n",
    "        # Fetch the data\n",
    "        x_split = globals()[f'x_{split}']\n",
    "\n",
    "        # STEP 2: Arcsinh\n",
    "        x_split_arcsinh = torch.arcsinh(x_split)\n",
    "\n",
    "        # Copy for norm\n",
    "        x_split_arcsinh_norm = x_split_arcsinh.clone()\n",
    "\n",
    "        # STEP 3: normalise by species variance\n",
    "        for species, indices in species_indices.items():\n",
    "            # Overwrite: normalise by sepcies variance\n",
    "            x_split_arcsinh_norm[:, indices] = x_split_arcsinh_norm[:, indices] / globals()[f\"arcsinh_std_x_{species}\"]\n",
    "\n",
    "        # SAVE\n",
    "        globals()[f'x_{split}_arcsinh_norm'] = x_split_arcsinh_norm\n",
    "\n",
    "    ### COMBINE WITH SPECIES raw data ###\n",
    "    for split in data_split:\n",
    "        for species, indices in species_indices.items():\n",
    "            # Fetch og x\n",
    "            x_split_species = globals()[f'x_{split}'][:, indices]\n",
    "\n",
    "            # Fetch arcsinh\n",
    "            x_split_arcsinh_norm = globals()[f'x_{split}_arcsinh_norm']\n",
    "\n",
    "            # Add relative rows - NOR for now\n",
    "            # x_split_species_relative = x_split_species.sum(dim = -1)\n",
    "\n",
    "            # Get indices of rows where the (OG) sum is zero or lower\n",
    "            # Remove from x and y \n",
    "            # zero_sum_indices = (x_split_species.sum(dim = -1) <= 0).nonzero(as_tuple = True)[0]\n",
    "            # print(split, species, zero_sum_indices.shape[0])\n",
    "            # any_under_zero_indices = (x_split_species < 0).any(dim = - 1).nonzero(as_tuple = True)[0]\n",
    "            # print(split, species, any_under_zero_indices.shape[0])\n",
    "\n",
    "            # Combine data\n",
    "            x_split_species_combined_data = torch.concat((x_split_arcsinh_norm, x_split_species), dim = -1)\n",
    "            print(x_split_species_combined_data.shape)\n",
    "\n",
    "            # Write\n",
    "            globals()[f'x_{split}_{species}_combi'] = x_split_species_combined_data\n",
    "\n",
    "# Preprocesses x_train, x_val, x_test to output\n",
    "# x_train_arcsinh_norm, x_val_arcsinh_norm, x_test_arcsinh_norm\n",
    "preprocess_x()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fff8010a",
   "metadata": {},
   "source": [
    "torch.set_printoptions(precision = 5, sci_mode = False)\n",
    "\n",
    "mean_per_column = x_train_arcsinh_norm.mean(dim=0)\n",
    "std_per_column = x_train_arcsinh_norm.std(dim=0)\n",
    "\n",
    "print(\"Means:\", mean_per_column)\n",
    "print(\"Stds:\", std_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7588d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_y():\n",
    "    for split in data_split:\n",
    "\n",
    "        # Fetch the data\n",
    "        x_split = globals()[f'x_{split}']\n",
    "        y_split = globals()[f'y_{split}']\n",
    "\n",
    "        # STEP 1: DELTA\n",
    "        y_delta_split = y_split - x_split\n",
    "\n",
    "        # STEP 2: Split into species\n",
    "        for species, indices in species_indices.items():\n",
    "\n",
    "            # Fetch y delta\n",
    "            y_delta_split_species = y_delta_split[:, indices]\n",
    "\n",
    "            # SAVE \n",
    "            globals()[f'y_delta_{split}_{species}'] = y_delta_split_species\n",
    "\n",
    "preprocess_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6ec70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "### MODEL ###\n",
    "#############\n",
    "\n",
    "class Transition_model_species_full_input(nn.Module):\n",
    "    def __init__(self, out_features, width, depth = 2, bias = 13.0):\n",
    "        super(Transition_model_species_full_input, self).__init__()\n",
    "        # this is the self transition bias, added to the logits (prior knowledge), high val\n",
    "        self.bias = bias\n",
    "        # define to reshape Transition matrix\n",
    "        self.out_features = out_features\n",
    "        # define this once and reuse\n",
    "        self.transition_identity = torch.eye(out_features).unsqueeze(0)\n",
    "        self.eps = 1e-8\n",
    "\n",
    "        # This model always takes 24 inputs \n",
    "        self.fc_in = nn.Linear(in_features = 24, out_features = width)\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(depth -1):\n",
    "            self.hidden_layers.append(nn.ReLU())\n",
    "            self.hidden_layers.append(nn.Linear(in_features = width, out_features = width))\n",
    "            self.hidden_layers.append(nn.ReLU())\n",
    "\n",
    "        # for the transition matrix, we want to have a square matrix, 1 for scale factor\n",
    "        self.fc_out = nn.Linear(in_features = width, out_features = (out_features * out_features))\n",
    "\n",
    "        # Set all model parameters to double precision\n",
    "        self.to(torch.float64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is shape(batch_size, 24 + species_features)\n",
    "        # ensure double\n",
    "        x = x.to(torch.float64)\n",
    "\n",
    "        # Split the input into two parts\n",
    "        x_for_network = x[:, :24]\n",
    "        x_for_transition = x[:, 24:] # may be 4 or 5\n",
    "\n",
    "        # Pass input into first layer shape(batch_size, 24)\n",
    "        state = self.fc_in(x_for_network)\n",
    "\n",
    "        for layer in self.hidden_layers:\n",
    "            state = layer(state)\n",
    "\n",
    "        logits = self.fc_out(state)\n",
    "\n",
    "        # Reshape to get (batch_size, out_features, out_features)\n",
    "        logits = logits.view(-1, self.out_features, self.out_features)\n",
    "        # print(logits[0])\n",
    "\n",
    "        if torch.isnan(logits).any():\n",
    "            print(\"NaN detected at logits!\")\n",
    "        if torch.isinf(logits).any():\n",
    "            print(\"Inf detected at logits!\")\n",
    "\n",
    "        # Add the bias to the diagonal (self transitions) with in-place operation\n",
    "        logits.diagonal(dim1 = -2, dim2 = -1).add_(self.bias)\n",
    "        # print(logits[0])\n",
    "\n",
    "        # Apply softmax across each row so that column values of that row (last dim) add to 1\n",
    "        # rows add to 1 (From : To): 100% of the source are redistributed\n",
    "        # PREVIOUSLY ISSUE (had dim = -1 before which was wrong)\n",
    "        transition_matrix = F.softmax(logits, dim = -2)\n",
    "\n",
    "        # Transition matrix without self-transitions\n",
    "        # Repeat for batch_size\n",
    "        transition_matrix_no_diag = transition_matrix - self.transition_identity.repeat(transition_matrix.shape[0], 1, 1).to(device)\n",
    "\n",
    "        # Multiply the input by the transition matrix without diagonal: bmm or matmul work\n",
    "        deltas = torch.matmul(transition_matrix_no_diag, x_for_transition.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # return (batch_size, out_features)\n",
    "        return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34f83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transition_model_species_full_input(out_features = 5, width = 64, depth = 2).to(device)\n",
    "out = model(x_train_so4_combi[0:3].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f49d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transition_model_species_full_input(out_features = 5, width = 64, depth = 2).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Make sure its training data\n",
    "x_train = x_train_so4_combi.double().to(device)\n",
    "y_train = y_delta_train_so4.double().to(device)\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 256, shuffle = True)\n",
    "\n",
    "# Training loop\n",
    "epochs = 1\n",
    "\n",
    "### Validation data ###\n",
    "\n",
    "# Helper\n",
    "def n_random_row_incides(x, n = 5000):\n",
    "    \"\"\"Returns n random rows from x\"\"\"\n",
    "    # Default is 5000\n",
    "    indices = np.random.choice(x.shape[0], n, replace = False)\n",
    "    return indices\n",
    "\n",
    "# Fix indices for some validation\n",
    "val_row_indices = n_random_row_incides(x_val, n = 30000)\n",
    "\n",
    "x_val = x_val_so4_combi.double().to(device)\n",
    "y_val = y_delta_val_so4.double().to(device)\n",
    "\n",
    "x_val_subset = x_val[val_row_indices]\n",
    "# y only ever needed on cpu\n",
    "y_val_subset = y_val[val_row_indices].cpu()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        deltas = model(x_batch)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = torch.sqrt(criterion(deltas, y_batch))\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item()}')\n",
    "\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print(f'Epoch {epoch}, Batch {batch_idx}, Training RMSE Loss (og units): {loss.item():.4f}')\n",
    "\n",
    "        if batch_idx % 5000 == 0:\n",
    "            model.eval()\n",
    "\n",
    "            PRED_y_delta_val = model(x_val_subset.to(device)).detach().cpu()\n",
    "\n",
    "            print(\"Validation R2 Score on delta sample (og units):\")\n",
    "            print(f\"{r2(PRED_y_delta_val, y_val_subset).item():.4f}\")\n",
    "\n",
    "            print(\"Validation RMSE on delta sample (og units):\")\n",
    "            print(f\"{torch.sqrt(criterion(PRED_y_delta_val, y_val_subset)).item():.4f}\")\n",
    "\n",
    "            model.train()\n",
    "        \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, RMSE Loss: {loss.item():.4f}')\n",
    "\n",
    "    # overwrite after each epoch\n",
    "    # torch.save(model.state_dict(), os.path.join(\"models\", \"arcsinh_unitvar_transition_bc_10epochs.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02dabdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 commenced (0.00% completed)\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "model = Transition_model_species_full_input(out_features = 5, width = 64, depth = 2).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Make sure its training data\n",
    "x_train = x_train_so4_combi.double().to(device)\n",
    "y_train = y_delta_train_so4.double().to(device)\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 256, shuffle = True)\n",
    "\n",
    "### Validation data ###\n",
    "\n",
    "x_val = x_val_so4_combi.double().to(device)\n",
    "y_val = y_delta_val_so4.double().to(device)\n",
    "\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "# no shuffle needed\n",
    "val_loader = DataLoader(val_dataset, batch_size = 256, shuffle = False)\n",
    "\n",
    "# Initialise lists to track convergence \n",
    "loss_per_epoch = []\n",
    "r2_per_epoch = []\n",
    "r2_sk_per_epoch = []\n",
    "\n",
    "val_loss_per_epoch = []\n",
    "val_r2_per_epoch = []\n",
    "val_r2_sk_per_epoch = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs} commenced ({(epoch)/epochs*100:.2f}% completed)\")\n",
    "    model.train()\n",
    "\n",
    "    # Initlaise lists within this epoch\n",
    "    loss_per_batch = []\n",
    "    r2_per_batch = []\n",
    "    r2_sk_per_batch = []\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        deltas_batch = model(x_batch)\n",
    "        \n",
    "        # Calculate loss for one batch\n",
    "        loss_batch = torch.sqrt(criterion(deltas_batch, y_batch))\n",
    "\n",
    "        # https://pytorch.org/torcheval/stable/generated/torcheval.metrics.functional.r2_score.html\n",
    "        # code: https://pytorch.org/torcheval/main/_modules/torcheval/metrics/functional/regression/r2_score.html\n",
    "        # https://discuss.pytorch.org/t/r2-score-return-inf/181348/2\n",
    "        # order is different: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html \n",
    "\n",
    "        with torch.no_grad():\n",
    "            r2_batch = r2(deltas_batch, y_batch) # torch: pred, truth\n",
    "            r2_sk_batch = sklearn.metrics.r2_score(y_batch.cpu(), deltas_batch.cpu()) # sklearn: truth, pred\n",
    "        \n",
    "        # Backward pass\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_per_batch.append(loss_batch.item())\n",
    "        r2_per_batch.append(r2_batch.item())\n",
    "        r2_sk_per_batch.append(r2_sk_batch)\n",
    "    \n",
    "    loss_per_epoch.append(np.mean(loss_per_batch))\n",
    "    r2_per_epoch.append(np.mean(r2_per_batch))\n",
    "    r2_sk_per_epoch.append(np.mean(r2_sk_per_batch))\n",
    "    \n",
    "    # after each epoch\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Initlaise lists within this epoch\n",
    "        val_loss_per_batch = []\n",
    "        val_r2_per_batch = []\n",
    "        val_r2_sk_per_batch = []\n",
    "        \n",
    "        # Iterate over batches\n",
    "        for batch_idx, (val_x_batch, val_y_batch) in enumerate(val_loader):\n",
    "            \n",
    "            # Forward pass\n",
    "            val_deltas_batch = model(val_x_batch)\n",
    "            \n",
    "            # Calculate loss\n",
    "            val_loss_batch = torch.sqrt(criterion(val_deltas_batch, val_y_batch))\n",
    "            val_r2_batch = r2(val_deltas_batch, val_y_batch)\n",
    "            val_r2_sk_batch = sklearn.metrics.r2_score(val_y_batch.cpu(), val_deltas_batch.cpu())\n",
    "\n",
    "            val_loss_per_batch.append(val_loss_batch.item())\n",
    "            val_r2_per_batch.append(val_r2_batch.item())\n",
    "            val_r2_sk_per_batch.append(val_r2_sk_batch)\n",
    "\n",
    "        val_loss_per_epoch.append(np.mean(val_loss_per_batch))\n",
    "        val_r2_per_epoch.append(np.mean(val_r2_per_batch))\n",
    "        val_r2_sk_per_epoch.append(np.mean(val_r2_sk_per_batch))\n",
    "\n",
    "        # Back to training\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4556c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-inf\n",
      "-0.9971232645368815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kim/anaconda3/envs/aero/lib/python3.10/site-packages/sklearn/metrics/_regression.py:930: RuntimeWarning: divide by zero encountered in divide\n",
      "  output_scores = 1 - (numerator / denominator)\n"
     ]
    }
   ],
   "source": [
    "# nominator has zero var\n",
    "y_true = np.full((100,), fill_value = 1.)\n",
    "y_pred = np.random.randn(100)\n",
    "\n",
    "# sklearn order is truth pred: inf -> 0\n",
    "print(sklearn.metrics.r2_score(y_true, y_pred))\n",
    "# 0.0\n",
    "\n",
    "print(sklearn.metrics.r2_score(y_true, y_pred, force_finite = False))\n",
    "# -inf\n",
    "\n",
    "# swap: nominator now has zero var\n",
    "y_true = np.random.randn(100)\n",
    "y_pred = np.full((100,), fill_value = 1.) # constant prediction\n",
    "\n",
    "print(sklearn.metrics.r2_score(y_true, y_pred))\n",
    "# 0.0\n",
    "\n",
    "print(sklearn.metrics.r2_score(y_true, y_pred, force_finite = False))\n",
    "# -inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4cdbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8591448242.16085]\n",
      "[-8591448242.160776]\n",
      "[0.16124264001264285]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "np.mean(loss_per_batch)\n",
    "\n",
    "print(val_r2_per_epoch)\n",
    "print(val_r2_sk_per_epoch)\n",
    "print(r2_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a7d49bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-12402.343079553524,\n",
       " -979.7851831959051,\n",
       " -330.62210283100313,\n",
       " -239.16007511027024,\n",
       " -190.13046509928057,\n",
       " -208.49904914766915,\n",
       " -215.99040973155306,\n",
       " -135.46098184666948,\n",
       " -150.9365601862619,\n",
       " -113.74633284246056,\n",
       " -136.89235969094938,\n",
       " -341.8866414527608,\n",
       " -587.5110357730935,\n",
       " -1211.4174874729165,\n",
       " -1624.3690802078136,\n",
       " -1453.4613763419268,\n",
       " -888.7108147711381,\n",
       " -1006.3405409171377,\n",
       " -1042.0245894519458,\n",
       " -683.3621926628118,\n",
       " -361.24026781688184,\n",
       " -191.107635984423,\n",
       " -183.4189858883984,\n",
       " -218.49928445139957,\n",
       " -202.58827949955938,\n",
       " -166.31770769766632,\n",
       " -228.7571434762694,\n",
       " -154.86823583327492,\n",
       " -130.11970363374772,\n",
       " -141.51343864368124,\n",
       " -186.1927286831611,\n",
       " -415.5382838900863,\n",
       " -457.1504370308132,\n",
       " -203.78597062191284,\n",
       " -97.6195946245003,\n",
       " -103.40973261032691,\n",
       " -132.4745123533225,\n",
       " -201.0353907457187,\n",
       " -351.84886555909475,\n",
       " -211.73398401185676,\n",
       " -155.87129571843383,\n",
       " -194.71379727006257,\n",
       " -299.6539399500774,\n",
       " -307.9164946477896,\n",
       " -334.05081727161274,\n",
       " -626.9507312500416,\n",
       " -847.4597869878708,\n",
       " -724.6393449661332,\n",
       " -495.05234391810774,\n",
       " -332.7527647803396,\n",
       " -232.6955368507583,\n",
       " -198.10156159488128,\n",
       " -539.2626410418154,\n",
       " -1580.226855194837,\n",
       " -6824.31994745186,\n",
       " -8513.512335221541,\n",
       " -10627.820570984595,\n",
       " -9340.707900358588,\n",
       " -9002.303430043952,\n",
       " -9884.218679832218,\n",
       " -7545.71309520482,\n",
       " -3861.5998547804675,\n",
       " -2253.0993141830304,\n",
       " -636.4873907463584,\n",
       " -590.3900822001974,\n",
       " -2104.648111392891,\n",
       " -14416.949521117693,\n",
       " -17510.60962610272,\n",
       " -19987.520986813768,\n",
       " -34785.14708534551,\n",
       " -81201.04426257401,\n",
       " -28.107256656765962,\n",
       " -73753.0306888297,\n",
       " -9429.949950684942,\n",
       " -3021.8553343939748,\n",
       " -1319.8637996924326,\n",
       " -372.37108779149287,\n",
       " -216.0251694477136,\n",
       " -130.31009318720825,\n",
       " -122.28113923155692,\n",
       " -136.84207654208524,\n",
       " -100.26199953075422,\n",
       " -146.7558108173057,\n",
       " -126.2329018900029,\n",
       " -99.78729245342257,\n",
       " -172.70277567004322,\n",
       " -174.9353616975508,\n",
       " -121.64786940018936,\n",
       " -160.0698143177247,\n",
       " -178.44777587813306,\n",
       " -119.09295388304695,\n",
       " -111.46834365641193,\n",
       " -113.44170117024609,\n",
       " -77.58380474819494,\n",
       " -50.345480295716015,\n",
       " -88.36807497614654,\n",
       " -93.69274148246515,\n",
       " -72.78078786877833,\n",
       " -59.99619680398905,\n",
       " -47.219511796604664,\n",
       " -28.94471384790079,\n",
       " -19.741124569317805,\n",
       " -20.896763122226837,\n",
       " -36.535144093024044,\n",
       " -89.91710173373592,\n",
       " -47.954012955823146,\n",
       " -45.60259219140608,\n",
       " -70.63186901649557,\n",
       " -92.19810216031613,\n",
       " -110.11685650187344,\n",
       " -88.87575954016462,\n",
       " -30.5663762065686,\n",
       " -21.363622669144725,\n",
       " -34.45949055577121,\n",
       " -39.41727743972245,\n",
       " -35.0177242635951,\n",
       " -43.584745962720305,\n",
       " -86.0899919287333,\n",
       " -79.67355184515203,\n",
       " -38.183277832374614,\n",
       " -27.64129490523476,\n",
       " -22.846875725857636,\n",
       " -20.631497956327383,\n",
       " -29.776822317969636,\n",
       " -32.97024633284492,\n",
       " -41.732072021965145,\n",
       " -32.73946233283628,\n",
       " -56.57994903378485,\n",
       " -100.07895896415346,\n",
       " -173.66508696196323,\n",
       " -219.6943545987816,\n",
       " -320.19476980515236,\n",
       " -410.52417364420523,\n",
       " -387.85657123001516,\n",
       " -609.610037126781,\n",
       " -1114.3843225228018,\n",
       " -1095.88233651079,\n",
       " -2119.5221458561855,\n",
       " -3462.4280605771733,\n",
       " -2430.1386597802575,\n",
       " -8347.781281919357,\n",
       " -11345.20375547338,\n",
       " -42640.89859091688,\n",
       " -38.54889237427326,\n",
       " -1828.7946121702705,\n",
       " -204.36886718015475,\n",
       " -96.28999843794702,\n",
       " -61.8005454309976,\n",
       " -115.51268943344867,\n",
       " -185.8297053284592,\n",
       " -134.391488841002,\n",
       " -94.31309744169394,\n",
       " -76.89494687953326,\n",
       " -60.939041112493875,\n",
       " -50.508766448510926,\n",
       " -44.96213831605633,\n",
       " -45.5033578974584,\n",
       " -30.083167309716128,\n",
       " -26.144736946876122,\n",
       " -20.925121411554855,\n",
       " -20.864234164758784,\n",
       " -16.831192974761695,\n",
       " -11.69983749316746,\n",
       " -12.335633820054701,\n",
       " -17.179485983788428,\n",
       " -14.73090100115579,\n",
       " -16.077952040141035,\n",
       " -17.64227670969123,\n",
       " -14.501431257715637,\n",
       " -10.579697384082156,\n",
       " -9.371238410669745,\n",
       " -6.79903764363587,\n",
       " -6.695901830707982,\n",
       " -7.839027548936317,\n",
       " -5.266004596474737,\n",
       " -4.059464943053891,\n",
       " -3.643691677885859,\n",
       " -2.602504424027373,\n",
       " -1.1786204949812709,\n",
       " -0.1697124270107668,\n",
       " -0.18623890029024995,\n",
       " -1.0897982372453652,\n",
       " -2.2902646028779725,\n",
       " -2.3953208031175395,\n",
       " -4.772563715761363,\n",
       " -5.873863831664992,\n",
       " -6.503644964618651,\n",
       " -9.565567292104438,\n",
       " -7.935195065207978,\n",
       " -5.685460041732083,\n",
       " -4.4955420098905545,\n",
       " -3.640800167787726,\n",
       " -3.8868462710036473,\n",
       " -4.186689694467601,\n",
       " -4.630453309758511,\n",
       " -5.998538247512459,\n",
       " -7.431305949679654,\n",
       " -16.088362722276884,\n",
       " -15.620988793596078,\n",
       " -14.99200263786903,\n",
       " -8.55584791007654,\n",
       " -18.588502076191546,\n",
       " -21.160414066099765,\n",
       " -34.23018067718853,\n",
       " -34.721093397009994,\n",
       " -23.539789661428017,\n",
       " -49.68637566662225,\n",
       " -140.31625805715566,\n",
       " -203.16760521247224,\n",
       " -241.81510913129583,\n",
       " -516.680249439846,\n",
       " -433.80076128421376,\n",
       " -950.2797048097822,\n",
       " -2731.98164944872,\n",
       " -2631.3465582886993,\n",
       " -14.708212457916307,\n",
       " -335.9737504939653,\n",
       " -36.4935066344991,\n",
       " -37.491234966591115,\n",
       " -17.320302558125174,\n",
       " -18.87138671225228,\n",
       " -19.804514688362268,\n",
       " -14.593295326362545,\n",
       " -14.81233236629707,\n",
       " -11.911902182733607,\n",
       " -10.807212638881223,\n",
       " -12.716759017643877,\n",
       " -11.12127491375589,\n",
       " -10.004007554917887,\n",
       " -5.538741867046437,\n",
       " -5.572776517514884,\n",
       " -5.38876563592493,\n",
       " -5.511880885735936,\n",
       " -228.42502336138688,\n",
       " -132.32575797166967,\n",
       " -3.878192283979274,\n",
       " -78.22240529647088,\n",
       " -3.6576626315772627,\n",
       " -407.6447566018445,\n",
       " -57.56151863003729,\n",
       " -22.104326743965544,\n",
       " -1.0263597427881632,\n",
       " -1.0620080450981455,\n",
       " -18.537545705939504,\n",
       " -35.81927078188902,\n",
       " -11.878401196453451,\n",
       " -0.6095042099143269,\n",
       " -18.284407647872023,\n",
       " -10.188926486026052,\n",
       " -36.903694069973646,\n",
       " -7.932484743735968,\n",
       " -12.024008182626497,\n",
       " -11.215233002670988,\n",
       " -0.5022991133157998,\n",
       " -18.380632793964356,\n",
       " -30.70200729999821,\n",
       " -13.12678093207629,\n",
       " -23.107507238608363,\n",
       " -77.51466455575246,\n",
       " -60.267511943809424,\n",
       " -55.040815089549675,\n",
       " -166.91293990428383,\n",
       " -1.6213697118841055,\n",
       " -2.3630689607762143,\n",
       " -3.5406812779110552,\n",
       " -3.117004693544753,\n",
       " -2.791304335077298,\n",
       " -2.8591340138530805,\n",
       " -3.1020273351575667,\n",
       " -3.9955184531453227,\n",
       " -4.30788332645715,\n",
       " -4.573674355395407,\n",
       " -2.7632735032659377,\n",
       " -5.745658510139823,\n",
       " -6.723662454215632,\n",
       " -7.404530899195801,\n",
       " -5.657776554785583,\n",
       " -3.885695738913057,\n",
       " -6.239874503658167,\n",
       " -16.17166164143561,\n",
       " -29.98202599071447,\n",
       " -87.01963399328663,\n",
       " -237.86764793442458,\n",
       " -274.3535609877256,\n",
       " -258.65617651958985,\n",
       " -195.2240695404315,\n",
       " -203.9576796761106,\n",
       " -13146.79237867525,\n",
       " -14922361.698418433,\n",
       " -244.58298025507892,\n",
       " -14956.387495408073,\n",
       " -2953.6799157627424,\n",
       " -944.5686005818137,\n",
       " -442.74409800002496,\n",
       " -6.605917622160918,\n",
       " -5.206924700725301,\n",
       " -435.0858410214187,\n",
       " -149.75529188565253,\n",
       " -206.56396253107204,\n",
       " -4.482411882921509,\n",
       " -4.167494537540936,\n",
       " -231.8674630380615,\n",
       " -2.625509557581462,\n",
       " -196.9193657192514,\n",
       " -36.30569305282163,\n",
       " -0.6795925403959225,\n",
       " -0.48526127359740834,\n",
       " -0.26624257826506653,\n",
       " -13.159620365635524,\n",
       " -0.14966615044663537,\n",
       " -42.320489645547056,\n",
       " -68.73493185210164,\n",
       " -15.139106615602298,\n",
       " -7.490118876169033,\n",
       " -11.289660125095013,\n",
       " -15.916295756457362,\n",
       " -16.78566926586281,\n",
       " -30.074794183087402,\n",
       " -18.15989822260918,\n",
       " -8.741461442583049,\n",
       " -15.039711708048907,\n",
       " -13.79282425023572,\n",
       " -10.383093230566269,\n",
       " -24.95482042102748,\n",
       " -14.007335850231744,\n",
       " -10.71063824703565,\n",
       " -18.15759844641479,\n",
       " -21.951707654424542,\n",
       " -4.417130318075821,\n",
       " -9.051762667084713,\n",
       " -10.798923015090969,\n",
       " -10.085250691142772,\n",
       " -7.587189894891443,\n",
       " -53.3192804768147,\n",
       " -9.894088342120746,\n",
       " -0.523640420779687,\n",
       " -0.3868379427561949,\n",
       " -91.93841457798796,\n",
       " -115.97838745500701,\n",
       " -1.9219390419925297,\n",
       " -1.6625769729479511,\n",
       " -2.2508530467688805,\n",
       " -2.238456610742733,\n",
       " -2.5196539014508645,\n",
       " -1.933556273743823,\n",
       " -4.509034805307822,\n",
       " -6.414246840638226,\n",
       " -5.83773459267872,\n",
       " -4.818605395330171,\n",
       " -4.863908075180052,\n",
       " -7.909808654975552,\n",
       " -1701.9431161639945,\n",
       " -27.30020619270166,\n",
       " -56.89702412714816,\n",
       " -117.15605957244557,\n",
       " -180.05262141254462,\n",
       " -797.1581649879442,\n",
       " -67995.87226817037,\n",
       " -80229.49848181753,\n",
       " -60.70695935911535,\n",
       " -138.97191102783634,\n",
       " -12222.5218612298,\n",
       " -2330.803221469318,\n",
       " -1258.909639722118,\n",
       " -488.16086412147916,\n",
       " -343.3224655703275,\n",
       " -71.31642219756426,\n",
       " -113.23610453769774,\n",
       " -1.946393646153067,\n",
       " -302.11019142524685,\n",
       " -328.88670413493503,\n",
       " -1.5459783587430014,\n",
       " -194.4786536927898,\n",
       " -88.29204787146153,\n",
       " -65.19564491413527,\n",
       " -15.9368525579074,\n",
       " -10.674414411271453,\n",
       " 0.04601164485743303,\n",
       " -0.09398524338974949,\n",
       " -6.7180658960286355,\n",
       " -1.657559510373862,\n",
       " -4.785519664871925,\n",
       " -18.0910587395433,\n",
       " -16.52400166590114,\n",
       " -11.010678957788212,\n",
       " -8.088926130016459,\n",
       " -10.846782078594195,\n",
       " -11.944985039709596,\n",
       " -16.040755517612638,\n",
       " -15.80281801407097,\n",
       " -10.106084965507005,\n",
       " -16.392349562211514,\n",
       " -41.80856135817979,\n",
       " -19.93621674170428,\n",
       " -21.549728390403722,\n",
       " -23.77351534499327,\n",
       " -8.464698019583853,\n",
       " -13.62558087933812,\n",
       " -9.533231767728156,\n",
       " -14.317368686854214,\n",
       " -10.10979984714616,\n",
       " -4.505754152705657,\n",
       " -4.464612348880538,\n",
       " -3.4773744645917573,\n",
       " 0.04222325414524164,\n",
       " -0.24527303517802074,\n",
       " -0.7558464612204839,\n",
       " -4.5194808283964205,\n",
       " -0.08926909577799633,\n",
       " -77.61662987754644,\n",
       " -244.7748303562113,\n",
       " -1.0314364439918022,\n",
       " -62.81714179991949,\n",
       " -2.4905355789420964,\n",
       " -158.60787639615862,\n",
       " -27.976754923741765,\n",
       " -2.2346211600074475,\n",
       " -89.73146921161015,\n",
       " -241.85041731957978,\n",
       " -486.8566940544241,\n",
       " -5.258725200866175,\n",
       " -5.614001493461836,\n",
       " -8.973606911869918,\n",
       " -22.448429757307583,\n",
       " -45.66809456063983,\n",
       " -72.1232069880758,\n",
       " -84.91074207899237,\n",
       " -131.45175372629947,\n",
       " -151.97804682971818,\n",
       " -4953.7103938671735,\n",
       " -9806.009311833926,\n",
       " -4861.750560294475,\n",
       " -8798.2011437834,\n",
       " -3301.280002493223,\n",
       " -436.4618857627817,\n",
       " -27.733668365237623,\n",
       " -435.63004027325576,\n",
       " -258.1751750616292,\n",
       " -2.895429615845032,\n",
       " -102.18247563830818,\n",
       " -1.6057319290838208,\n",
       " -1.267601590637621,\n",
       " -1.1660375806751593,\n",
       " -43.122333178322286,\n",
       " -22.190447641211286,\n",
       " -396.0007809527284,\n",
       " -367.66502251116356,\n",
       " 0.23504336626504913,\n",
       " -14.218809222428941,\n",
       " -3.7986505794632803,\n",
       " -23.49508281452217,\n",
       " -14.90362674610705,\n",
       " -24.22385586649893,\n",
       " -28.06747036715081,\n",
       " -11.099217257071944,\n",
       " -13.798491464864412,\n",
       " -7.125246403580954,\n",
       " -8.63472347489082,\n",
       " -21.671796244245158,\n",
       " -18.37206105259366,\n",
       " -19.332711386229477,\n",
       " -20.014638743223987,\n",
       " -26.52363853285447,\n",
       " -11.57181531121856,\n",
       " -35.74077463272103,\n",
       " -23.76767746714247,\n",
       " -12.124128281554977,\n",
       " -45.69376423639825,\n",
       " -9.283635974202884,\n",
       " -15.094900136121627,\n",
       " -35.632581751293365,\n",
       " -19.298615621395253,\n",
       " -6.543770679282524,\n",
       " -7.832473986489023,\n",
       " -1.7429853791957624,\n",
       " -0.29213315374753734,\n",
       " -0.24297629030671414,\n",
       " 0.23714601698722276,\n",
       " -0.07440704100031312,\n",
       " -4.791018833531838,\n",
       " -1.1827615385912367,\n",
       " -34.044183305450204,\n",
       " -103.57689943623627,\n",
       " -1.0168592702134744,\n",
       " -1.8354479309727254,\n",
       " -1.6389585686366377,\n",
       " -1.2219065219694107,\n",
       " -2.8423931164675995,\n",
       " -3.446336045126207,\n",
       " -4.79128870544555,\n",
       " -5.353481589689666,\n",
       " -6.31459118382233,\n",
       " -6.733218810170581,\n",
       " -10.673047721419865,\n",
       " -17.23240210360943,\n",
       " -21.741509255063928,\n",
       " -27.307772227942326,\n",
       " -29.701376698913425,\n",
       " -158.40579207334488,\n",
       " -31.501568786306336,\n",
       " -39.65394754376623,\n",
       " -45.34462116421257,\n",
       " -94.18812092466749,\n",
       " -56.069650306738744,\n",
       " -2344.8343607032375,\n",
       " -943.1586062464958,\n",
       " -47.183305357785265,\n",
       " -171.39190812606859,\n",
       " -140.62261932646268,\n",
       " -98.65439729166833,\n",
       " -198.0653971441737,\n",
       " -44.68833453564541,\n",
       " -3.6840170169512625,\n",
       " 0.26235153058024435,\n",
       " -14.719059430615896,\n",
       " -6.683814545000695,\n",
       " -61.04191798335584,\n",
       " -29.39553929546033,\n",
       " -30.48073072111568,\n",
       " -11.768433257658273,\n",
       " -11.386568608994676,\n",
       " -11.39308442757047,\n",
       " -12.658377896697102,\n",
       " -12.586454327242425,\n",
       " -11.701975131257647,\n",
       " -19.86428603316614,\n",
       " -7.713628821740118,\n",
       " -10.156129519581665,\n",
       " -3.755012296205114,\n",
       " -5.34746820934327,\n",
       " -19.663991372217332,\n",
       " -29.377996683062253,\n",
       " -12.510633020683903,\n",
       " -7.993565636920245,\n",
       " -6.0193952131868,\n",
       " -5.276103768059992,\n",
       " -22.447667402904838,\n",
       " -36.184486265764555,\n",
       " -15.93420699516781,\n",
       " -31.689297210295727,\n",
       " -38.72873608753016,\n",
       " -0.4014712585887432,\n",
       " -11.805964522727757,\n",
       " -18.706208762651354,\n",
       " -4.6726068307391575,\n",
       " -1.3376556015889685,\n",
       " -2.7319994761357007,\n",
       " 0.244457444070839,\n",
       " 0.41326734727409314,\n",
       " 0.5386395144406685,\n",
       " 0.29972366558034336,\n",
       " -0.12405511566782268,\n",
       " 0.40011838756134627,\n",
       " -8.319325037716144,\n",
       " -1.567017704294705,\n",
       " -0.5121988189470492,\n",
       " -2.615326221731159,\n",
       " -2.760565208536396,\n",
       " -2.0261816991895474,\n",
       " -2.68965533403112,\n",
       " -153.95756221130006,\n",
       " -2.3865312875592166,\n",
       " -157.22261105465878,\n",
       " -2.2830835943465573,\n",
       " -3.2964973121701844,\n",
       " -13.054480218014708,\n",
       " -24.984982567427558,\n",
       " -8.162809169895995,\n",
       " -46.74065790959679,\n",
       " -12.661715287217444,\n",
       " -28.512518714654107,\n",
       " -22.92721154735496,\n",
       " -15.52901359112297,\n",
       " -12.866094220295405,\n",
       " -22.381125070535823,\n",
       " -9.147278785839621,\n",
       " -81.98642064107185,\n",
       " -530.5563407307643,\n",
       " -191.8149650005265,\n",
       " -117.63906169522936,\n",
       " -376.59218540497886,\n",
       " -132.90449630220252,\n",
       " -42.49277389478796,\n",
       " -12.973934848357908,\n",
       " -47.464056069757746,\n",
       " -57.71287702390416,\n",
       " -21.950449097823842,\n",
       " -6.701380825795629,\n",
       " -12.065591384107126,\n",
       " -11.788505760533592,\n",
       " -6.802587609609914,\n",
       " -4.867965221929073,\n",
       " -4.582004011484814,\n",
       " -8.152645963056974,\n",
       " -4.835074086960437,\n",
       " -8.689560877880277,\n",
       " -11.903182216713626,\n",
       " -7.892609731026786,\n",
       " -3.106941788883817,\n",
       " -13.25091493171586,\n",
       " -4.218253438626783,\n",
       " -6.289690336678137,\n",
       " -9.714815734755032,\n",
       " -36.0379083566847,\n",
       " -11.987453956537294,\n",
       " -9.147741874470452,\n",
       " -7.698291753629988,\n",
       " -16.095399890299834,\n",
       " -122.74371421734095,\n",
       " -194.81907478912962,\n",
       " -25.576361621690065,\n",
       " -45.02089606028046,\n",
       " -9.633864116793294,\n",
       " -23.124539187707253,\n",
       " -27.68326029402174,\n",
       " -26.415049067750335,\n",
       " -0.062296791224005464,\n",
       " -1.668779250162648,\n",
       " -6.466726835910516,\n",
       " 0.4198017710298972,\n",
       " -1.1771085510333812,\n",
       " 0.5198028211460315,\n",
       " 0.2565167132463174,\n",
       " 0.23173332437207375,\n",
       " 0.1701316383430213,\n",
       " 0.22339406656504757,\n",
       " 0.2607003626860006,\n",
       " -2.3805376076382823,\n",
       " -0.39988093409031134,\n",
       " -0.17264458862668663,\n",
       " -0.06032983560311804,\n",
       " -0.6283886869164924,\n",
       " -0.6775523398039885,\n",
       " -2.308821925248596,\n",
       " -1.1066846375572348,\n",
       " -2.4704532832700097,\n",
       " -2.5098870011968106,\n",
       " -5.497430034476418,\n",
       " -90.42677102711063,\n",
       " -2.8090768561141553,\n",
       " -56.062457452483876,\n",
       " -2.196800433804116,\n",
       " -3.7285154640040306,\n",
       " -5.343524025546908,\n",
       " -2.8739678414728105,\n",
       " -5.7397736167677875,\n",
       " -17.866192472775513,\n",
       " -448.9843695915517,\n",
       " -3697.495758914572,\n",
       " -211.2315581323096,\n",
       " -184.31163823304996,\n",
       " -130.37530800304057,\n",
       " -81.00772423485094,\n",
       " -85.22469212919225,\n",
       " -50.6841618489564,\n",
       " -45.778016120708195,\n",
       " -36.846120343479825,\n",
       " -22.805951495316286,\n",
       " -21.00511237544337,\n",
       " -11.118683865639117,\n",
       " -6.828510927661037,\n",
       " -5.257506088230715,\n",
       " -6.030318140366648,\n",
       " -5.431360214647891,\n",
       " -4.283442554661439,\n",
       " -5.16517854213451,\n",
       " -2.0725456194616205,\n",
       " -2.239104017497941,\n",
       " -3.2701844106602365,\n",
       " -3.5318166963275153,\n",
       " -3.051427639876942,\n",
       " -11.390604761192623,\n",
       " -4.522638483292438,\n",
       " -7.988463753196918,\n",
       " -17.69105716477759,\n",
       " -32.139649605413794,\n",
       " -10.084308884155151,\n",
       " -7.676216014880296,\n",
       " -11.482399100967932,\n",
       " -9.939941930334607,\n",
       " -65.68990759201648,\n",
       " -77.40931381034473,\n",
       " -33.0753553539711,\n",
       " -26.252343589363544,\n",
       " -19.262229892844992,\n",
       " -2.6221132293973914,\n",
       " -16.28670757032354,\n",
       " -21.931955895129633,\n",
       " -16.695172062414706,\n",
       " -5.33987428133196,\n",
       " -9.348455578483208,\n",
       " 0.26304011556419116,\n",
       " 0.4828831089536295,\n",
       " 0.5524049042205229,\n",
       " 0.5212601898974476,\n",
       " -7.747900029256861,\n",
       " -21.409884718680345,\n",
       " -0.23734830925249942,\n",
       " -0.846590460306,\n",
       " -2.2152780882008325,\n",
       " -1.049652051147427,\n",
       " -19.96334714959719,\n",
       " -9.355039238414946,\n",
       " -1.189337610091381,\n",
       " -3.256437222249338,\n",
       " -20.718091669558326,\n",
       " -27.52720725866547,\n",
       " -30.627451798435988,\n",
       " -1.0022161438304527,\n",
       " -2.263384752155899,\n",
       " -1.6153915660949785,\n",
       " -1.4339506026419813,\n",
       " -0.8924042051078104,\n",
       " -0.8378199084874621,\n",
       " -1.1761240320009256,\n",
       " -1.0437949008249148,\n",
       " -0.8581613932617438,\n",
       " -1.3106643948477028,\n",
       " -12.730790502952054,\n",
       " -3.5388172648621072,\n",
       " -312.3890724469321,\n",
       " -166.25128238633198,\n",
       " -84.4200795681441,\n",
       " -56.80912865009962,\n",
       " -60.430935477607115,\n",
       " -39.5683408712013,\n",
       " -27.879581507645224,\n",
       " -24.662571890358954,\n",
       " -20.955588649226062,\n",
       " -14.20091350641422,\n",
       " -11.993666438478787,\n",
       " -9.008674281361799,\n",
       " -9.624432431243443,\n",
       " -3.025515784832084,\n",
       " -4.6209821915437415,\n",
       " -2.804851269495317,\n",
       " -3.4378774629586473,\n",
       " -2.2971298444240746,\n",
       " -1.1124009044012506,\n",
       " -1.0635764123533744,\n",
       " -1.1329275110554087,\n",
       " -1.1915216484742546,\n",
       " -0.7119045750962842,\n",
       " -4.612999260748589,\n",
       " -10.879380344983355,\n",
       " -4.657656139078625,\n",
       " -1.7334811741947629,\n",
       " -6.937297642599489,\n",
       " -4.801064652573775,\n",
       " -6.8385832924389955,\n",
       " -3.632167178740415,\n",
       " -23.47653150816152,\n",
       " -26.895025934722657,\n",
       " -37.22270621377574,\n",
       " -28.315215817838588,\n",
       " -36.14965925930827,\n",
       " -5.841279734193883,\n",
       " -9.229567990228603,\n",
       " -14.310439159943016,\n",
       " -24.968295221110257,\n",
       " -6.011846860533778,\n",
       " -12.617260937739252,\n",
       " -1.055896485993617,\n",
       " 0.13486068165397352,\n",
       " 0.29093073249279633,\n",
       " 0.2084307495387263,\n",
       " -0.7173823689253354,\n",
       " -5.84796567445479,\n",
       " -0.7933991521674199,\n",
       " -0.14511193518111398,\n",
       " -3.0022823339368614,\n",
       " -1.110269809437288,\n",
       " -7.670789829201328,\n",
       " -6.232851733864698,\n",
       " -3.5820591437847944,\n",
       " -3.0429751718699425,\n",
       " -0.4177984988209939,\n",
       " -15.938760004361802,\n",
       " -7.328374519447367,\n",
       " -23.5436717495867,\n",
       " -23.841258613110277,\n",
       " -23.180263354222667,\n",
       " -41.44726522417635,\n",
       " -0.7296449019369314,\n",
       " -1.1716747200975457,\n",
       " -0.33471218314069284,\n",
       " -0.17921546645353917,\n",
       " -0.38750996423297673,\n",
       " -1.1573253920465325,\n",
       " -0.3646921671564885,\n",
       " -2.6371550605891856,\n",
       " -43.39917010068301,\n",
       " -317.24991612287,\n",
       " -75.00388553852125,\n",
       " -83.30114358915793,\n",
       " -80.24919136540751,\n",
       " -54.09121660058171,\n",
       " -38.136728195364924,\n",
       " -25.196530283114967,\n",
       " -19.83681721097453,\n",
       " -8.194271643491792,\n",
       " -6.961895903507721,\n",
       " -6.583281336736765,\n",
       " -5.2170165639754424,\n",
       " -6.417985257669093,\n",
       " -2.4865662472752357,\n",
       " -3.3754743829917766,\n",
       " -3.096238726761058,\n",
       " -1.5446149473066657,\n",
       " -1.1208656093990808,\n",
       " -0.4017701531988953,\n",
       " -3.8039178093091826,\n",
       " -0.6002235293777746,\n",
       " -0.9576651844863534,\n",
       " -1.9206584608787978,\n",
       " -13.075016639128014,\n",
       " -5.284684460614672,\n",
       " -7.516922603384648,\n",
       " -8.246504316188716,\n",
       " -5.3809076270165255,\n",
       " -5.602143871586734,\n",
       " -7.233153079243226,\n",
       " -7.339621483550817,\n",
       " -7.6949553595502875,\n",
       " -19.422887473958262,\n",
       " -47.463329539544794,\n",
       " -6.429295572744495,\n",
       " -30.35670116095982,\n",
       " -31.919000871662764,\n",
       " -9.395027202777786,\n",
       " -14.050845787472209,\n",
       " -11.321352943157018,\n",
       " -4.246615952878017,\n",
       " -2.317970761474759,\n",
       " -3.130979206544313,\n",
       " -1.21225914419461,\n",
       " -2.954747020641882,\n",
       " -4.827388226690724,\n",
       " -7.449010561926069,\n",
       " -1.8758951543355735,\n",
       " -3.6320959215300475,\n",
       " 0.15976768442339537,\n",
       " -0.7334086841446175,\n",
       " -0.5340657098528098,\n",
       " -2.466510499780488,\n",
       " -3.586073956845297,\n",
       " -2.423635780138921,\n",
       " -0.6520746362626643,\n",
       " -6.435303523608906,\n",
       " -4.906616010663903,\n",
       " -16.397000862853016,\n",
       " -9.064803388847896,\n",
       " -10.263156947639256,\n",
       " -3.3232123952721366,\n",
       " -5.049634683922973,\n",
       " -0.41838215884901775,\n",
       " -1.019103490937011,\n",
       " -0.18508592903387774,\n",
       " -0.09869561663259285,\n",
       " -0.37860138266272114,\n",
       " -1.579429045418545,\n",
       " 0.04339395874711523,\n",
       " -0.6240478460980519,\n",
       " -90.70552782730738,\n",
       " -1893.4867682610789,\n",
       " -89.57126392450816,\n",
       " -47.462760493060955,\n",
       " -46.27808521657782,\n",
       " -44.64867151748471,\n",
       " -43.052034461366716,\n",
       " -12.89933034975311,\n",
       " -11.218068620263388,\n",
       " -8.393677435726051,\n",
       " -6.57310547450265,\n",
       " -5.181815241209039,\n",
       " -6.210007068101996,\n",
       " -4.474230006098358,\n",
       " -6.574036535723943,\n",
       " -5.535301482126595,\n",
       " -3.8002453248378765,\n",
       " -2.347813796158488,\n",
       " -1.1518918560387343,\n",
       " -1.5875162878529925,\n",
       " -1.8491783233522234,\n",
       " -0.8320893128800998,\n",
       " -0.15341355692872977,\n",
       " 0.23122659612523094,\n",
       " -1.8423500593582234,\n",
       " -5.073392845970429,\n",
       " -6.144427996011066,\n",
       " -10.002802121176043,\n",
       " -10.264567414128859,\n",
       " -0.68270963021658,\n",
       " -8.425587802242571,\n",
       " -9.689155863801293,\n",
       " -4.992602248823043,\n",
       " -12.439376472675704,\n",
       " -15.684623310424584,\n",
       " -9.613138452385487,\n",
       " -8.901503569837388,\n",
       " -38.46597454711553,\n",
       " -1.9868582849415097,\n",
       " -7.632125505088427,\n",
       " -10.17943652375648,\n",
       " -6.662225953117824,\n",
       " -2.034772000179148,\n",
       " -1.0214524460635868,\n",
       " -0.684297487604742,\n",
       " -1.5479526644101649,\n",
       " -3.631102553758962,\n",
       " -1.894213574011772,\n",
       " -5.502430561506374,\n",
       " -2.2470682373377895,\n",
       " -0.5389499138859815,\n",
       " -2.7696258423248308,\n",
       " -2.3278140208332743,\n",
       " -2.5214010431423284,\n",
       " -2.575430067863733,\n",
       " -2.8435930569593566,\n",
       " -3.1678364611295766,\n",
       " -0.18566704113157678,\n",
       " -0.304913687099932,\n",
       " -25.189182009961,\n",
       " -13.422013654876688,\n",
       " -27.177526797322162,\n",
       " -2.9565838589039193,\n",
       " -37.869026632416684,\n",
       " -0.39356286374710736,\n",
       " -92.89859895392722,\n",
       " -0.3837946805533988,\n",
       " -0.36045310227785315,\n",
       " -1.935800619272926,\n",
       " -1.0273039474303083,\n",
       " 0.07944139690798405,\n",
       " -0.3061434207269348,\n",
       " -36.615844349449944,\n",
       " -228.57757057043491,\n",
       " -108.28126275821812,\n",
       " -84.66254632547674,\n",
       " -50.11118438173266,\n",
       " -32.43157138954885,\n",
       " -50.74546073945897,\n",
       " -8.530301951418062,\n",
       " -7.496341721211775,\n",
       " -7.601042153320374,\n",
       " -7.551201368826909,\n",
       " -5.706713544494649,\n",
       " -4.834474960240245,\n",
       " -1.8604918612362766,\n",
       " -5.259993115477226,\n",
       " -1.9286443993429603,\n",
       " -2.8081957277483243,\n",
       " -1.6582219372617621,\n",
       " -0.4318017774503458,\n",
       " -1.1271472167405543,\n",
       " -0.08898412362560193,\n",
       " -1.2711528305279367,\n",
       " -0.953801643326009,\n",
       " -0.38383439297948374,\n",
       " -2.1459656748134917,\n",
       " -10.42428832310424,\n",
       " -6.740526174916648,\n",
       " -12.66281700768086,\n",
       " -27.18830390426063,\n",
       " -8.100149890070156,\n",
       " -17.921929587476047,\n",
       " -16.765095474131886,\n",
       " -12.457146046923592,\n",
       " -8.038138893244316,\n",
       " -11.418854294379726,\n",
       " -15.787165265734245,\n",
       " -25.331965268525455,\n",
       " -54.02767981162257,\n",
       " -22.647996400706262,\n",
       " -19.39113832757403,\n",
       " -14.160018561633251,\n",
       " -7.591038130137929,\n",
       " -2.321354802691593,\n",
       " -5.826896831651748,\n",
       " -1.846315952139637,\n",
       " -3.57861462864604,\n",
       " -5.563194924200198,\n",
       " -8.409317623903885,\n",
       " -6.321849559573364,\n",
       " -6.037768032416633,\n",
       " -1.5776101958009163,\n",
       " -2.4254529987558353,\n",
       " -2.7922512240305606,\n",
       " -2.941085137058621,\n",
       " -1.120835510384645,\n",
       " -3.9092409604373786,\n",
       " -6.586622899654086,\n",
       " -11.472551883573644,\n",
       " -0.766837746054817,\n",
       " -1.8678305386992509,\n",
       " -11.78614076974107,\n",
       " -29.242456442149354,\n",
       " -9.137576920128009,\n",
       " -17.898652098653894,\n",
       " -0.4252661850985645,\n",
       " ...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_r2_sk_per_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30dae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a0c2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2783.3613309665216"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(val_deltas_batch.cpu(), val_y_batch.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d108f933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.3046e+12, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_r2_batch = r2(val_deltas_batch, val_y_batch)\n",
    "val_r2_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "025559c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1304649879639.6735839844, device='cuda:0', dtype=torch.float64)\n",
      "-17.39352084075829\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(precision=10, sci_mode=False)\n",
    "print(r2(val_deltas_batch, val_y_batch))\n",
    "print(r2_score(val_deltas_batch.cpu(), val_y_batch.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc363cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "decada5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(39.2647856420, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score_torch(val_deltas_batch, val_y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbdaba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def r2_score_torch(pred, true, force_finite = True):\n",
    "    # Flatten tensors\n",
    "    pred = pred.flatten()\n",
    "    true = true.flatten()\n",
    "    \n",
    "    # Calculate the total sum of squares (ss_total)\n",
    "    ss_total = torch.sum((true - true.mean())**2)\n",
    "    \n",
    "    # If ss_total is zero (all true values are identical), return R = 1 (perfect fit)\n",
    "    if ss_total == 0:\n",
    "        return torch.tensor(1.0)\n",
    "    \n",
    "    # Calculate the residual sum of squares (ss_residual)\n",
    "    ss_residual = torch.sum((true - pred)**2)\n",
    "    \n",
    "    # Standard formula for R\n",
    "    numerator = ss_total - ss_residual\n",
    "    denominator = ss_total\n",
    "    \n",
    "    if force_finite:\n",
    "        # If the denominator is zero, avoid division by zero and set R to 0\n",
    "        if denominator == 0:\n",
    "            return torch.tensor(0.0)\n",
    "        \n",
    "        # If the numerator is zero, it implies perfect predictions, so set R to 1\n",
    "        if numerator == 0:\n",
    "            return torch.tensor(1.0)\n",
    "\n",
    "        # If neither the numerator nor the denominator is zero, compute R normally\n",
    "        output_score = 1 - (numerator / denominator)\n",
    "        \n",
    "        # Ensure the output is finite\n",
    "        if torch.isinf(output_score) or torch.isnan(output_score):\n",
    "            return torch.tensor(0.0)\n",
    "        \n",
    "        return output_score\n",
    "\n",
    "    else:\n",
    "        # Standard formula without forcing finite values\n",
    "        return 1 - (numerator / denominator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
